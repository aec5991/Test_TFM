[benchmark0]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 1
models = VGG-Face
th_models = 0.6

[benchmark1]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 1
models = Facenet
th_models = 10

[benchmark2]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 1
models = Facenet512
th_models = 23.56

[benchmark3]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 1
models = OpenFace
th_models = 0.55

[benchmark4]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 1
models = DeepFace
th_models = 64

[benchmark5]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 1
models = ArcFace
th_models = 4.15

[benchmark6]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 1
models = Dlib
th_models = 0.6

[benchmark7]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 2
models = VGG-Face
th_models = 0.6

[benchmark8]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 2
models = Facenet
th_models = 10

[benchmark9]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 2
models = Facenet512
th_models = 23.56

[benchmark10]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 2
models = OpenFace
th_models = 0.55

[benchmark11]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 2
models = DeepFace
th_models = 64

[benchmark12]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 2
models = ArcFace
th_models = 4.15

[benchmark13]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 2
models = Dlib
th_models = 0.6

[benchmark14]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 3
models = VGG-Face
th_models = 0.6

[benchmark15]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 3
models = Facenet
th_models = 10

[benchmark16]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 3
models = Facenet512
th_models = 23.56

[benchmark17]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 3
models = OpenFace
th_models = 0.55

[benchmark18]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 3
models = DeepFace
th_models = 64

[benchmark19]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 3
models = ArcFace
th_models = 4.15

[benchmark20]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = no
fd_type = 3
models = Dlib
th_models = 0.6

[benchmark21]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 1
models = VGG-Face
th_models = 0.6

[benchmark22]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 1
models = Facenet
th_models = 10

[benchmark23]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 1
models = Facenet512
th_models = 23.56

[benchmark24]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 1
models = OpenFace
th_models = 0.55

[benchmark25]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 1
models = DeepFace
th_models = 64

[benchmark26]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 1
models = ArcFace
th_models = 4.15

[benchmark27]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 1
models = Dlib
th_models = 0.6

[benchmark28]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 2
models = VGG-Face
th_models = 0.6

[benchmark29]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 2
models = Facenet
th_models = 10

[benchmark30]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 2
models = Facenet512
th_models = 23.56

[benchmark31]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 2
models = OpenFace
th_models = 0.55

[benchmark32]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 2
models = DeepFace
th_models = 64

[benchmark33]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 2
models = ArcFace
th_models = 4.15

[benchmark34]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 2
models = Dlib
th_models = 0.6

[benchmark35]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 3
models = VGG-Face
th_models = 0.6

[benchmark36]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 3
models = Facenet
th_models = 10

[benchmark37]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 3
models = Facenet512
th_models = 23.56

[benchmark38]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 3
models = OpenFace
th_models = 0.55

[benchmark39]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 3
models = DeepFace
th_models = 64

[benchmark40]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 3
models = ArcFace
th_models = 4.15

[benchmark41]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 1
fd_type = 3
models = Dlib
th_models = 0.6

[benchmark42]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 1
models = VGG-Face
th_models = 0.6

[benchmark43]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 1
models = Facenet
th_models = 10

[benchmark44]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 1
models = Facenet512
th_models = 23.56

[benchmark45]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 1
models = OpenFace
th_models = 0.55

[benchmark46]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 1
models = DeepFace
th_models = 64

[benchmark47]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 1
models = ArcFace
th_models = 4.15

[benchmark48]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 1
models = Dlib
th_models = 0.6

[benchmark49]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 2
models = VGG-Face
th_models = 0.6

[benchmark50]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 2
models = Facenet
th_models = 10

[benchmark51]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 2
models = Facenet512
th_models = 23.56

[benchmark52]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 2
models = OpenFace
th_models = 0.55

[benchmark53]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 2
models = DeepFace
th_models = 64

[benchmark54]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 2
models = ArcFace
th_models = 4.15

[benchmark55]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 2
models = Dlib
th_models = 0.6

[benchmark56]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 3
models = VGG-Face
th_models = 0.6

[benchmark57]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 3
models = Facenet
th_models = 10

[benchmark58]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 3
models = Facenet512
th_models = 23.56

[benchmark59]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 3
models = OpenFace
th_models = 0.55

[benchmark60]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 3
models = DeepFace
th_models = 64

[benchmark61]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 3
models = ArcFace
th_models = 4.15

[benchmark62]
clip = Clip5.m4v
path_database = Database/*
format_img_database = /*.png
predictor = shape_predictor_68_face_landmarks_GTX.dat
th_roi = 450
record_faces = no
steps_frame = 1
show_info = no
bs = yes
bs_type = 2
fd_type = 3
models = Dlib
th_models = 0.6

